{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26893962-4be5-4c03-a9f8-0db186871feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "# import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2573733-6170-4863-882a-d49f72ab8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv(\"data/plasticc_train_metadata.csv\")\n",
    "\n",
    "dftest = pd.read_csv(\"data/plasticc_test_metadata.csv\")\n",
    "\n",
    "dftest = dftest[:20000]\n",
    "\n",
    "dftest['target'] = dftest['true_target']\n",
    "\n",
    "dftrain = pd.concat([dftrain, dftest], axis=0, ignore_index=True)\n",
    "\n",
    "model_nums = {90:'SN Ia', 67:'SNIa-91bg', 52:'SNIax', 42:'SNII', 62:'SNIbc', 95:'SLSN-I', 15:'TDE', 64:'KN', 88:'AGN', 92:'RRL', 65:'M-dwarf', 16:'EB', 53:'Mira', 6:'muLens-Single', 991:'muLens-Binary', 992:'ILOT', 993:'CaRT', 994:'PISN', 995:'muLens-String'}\n",
    "\n",
    "sn_models = [90, 67, 52, 42, 62, 95, 15]\n",
    "\n",
    "dftrain = dftrain[dftrain['target'].isin(sn_models)]\n",
    "\n",
    "dftrain['target_names'] = dftrain['target'].map(model_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac94773-25f2-46bc-94b2-6b0e0086b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs = pd.read_csv(\"data/plasticc_train_lightcurves.csv\")\n",
    "lcs_test = pd.read_csv(\"data/plasticc_test_lightcurves_01.csv\")\n",
    "\n",
    "lcs = pd.concat([lcs, lcs_test[:3000000]], axis=0, ignore_index=True)\n",
    "\n",
    "# lcs = pd.merge(lcs, dftrain, on='object_id', how='inner')\n",
    "# lcs['passband']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b486de-42c8-4fa9-bc8f-d75884be1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['object_id', 'mjd', 'passband', 'flux', 'flux_err']\n",
    "columns2 = ['mjd', 'passband', 'flux', 'flux_err']\n",
    "# filter wavelengths in angstroms\n",
    "wavelengths = {\n",
    "    0: 3671.0,\n",
    "    1: 4827.0,\n",
    "    2: 6223.0,\n",
    "    3: 7546.0,\n",
    "    4: 8691.0,\n",
    "    5: 9712.0\n",
    "}\n",
    "\n",
    "lcs['passband'] = lcs['passband'].map(wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "579ba84f-1934-4203-a719-22a0bd5dcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Train Data\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "max_length = 352\n",
    "\n",
    "for id in dftrain['object_id']:\n",
    "    if len(lcs[lcs['object_id'] == id]) == 0:\n",
    "        continue\n",
    "    x_data.append(lcs[lcs['object_id'] == id][columns].reset_index())\n",
    "    y_data.append(dftrain[dftrain['object_id'] == id][['object_id', 'true_peakmjd']].values.tolist()[0])\n",
    "\n",
    "    # Expand light curve data to max length with 0s\n",
    "    while len(x_data[-1].index) < max_length: \n",
    "        x_data[-1].loc[len(x_data[-1].index)] = [len(x_data[-1].index), id, 0, 0, 0, 0]\n",
    "    x_data[-1] = x_data[-1][columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e094a252-0fbe-494a-a21a-df3c9b7abf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "for i in range(len(x_data)):\n",
    "    # try:\n",
    "    #     x_train[i] = x_train[i].values\n",
    "    # except AttributeError:\n",
    "    #     pass\n",
    "    y_data[i][1] -= 58999\n",
    "    y_data[i][1] /= 2000\n",
    "    for j in range(len(x_data[i])):\n",
    "        if x_data[i].loc[j]['mjd'] == 0:\n",
    "            continue\n",
    "        x_data[i].at[j, 'mjd'] -= 59000\n",
    "        x_data[i].at[j, 'mjd'] /= 2000\n",
    "        x_data[i].at[j, 'passband'] -= 3670\n",
    "        x_data[i].at[j, 'passband'] /= 6041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c083854b-5066-4208-a821-c710449e837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "     x_data, y_data, test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a3d5bf-aadc-485c-9679-2099cac1ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_test, y_test, test_size=0.5, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c501b971-a7c9-4e1e-8acf-4e5a1826b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_values = []\n",
    "for i in range(len(x_train)):\n",
    "    x_train_values.append([])\n",
    "    for row in x_train[i].values:\n",
    "        x_train_values[-1].append(row[1:])\n",
    "y_train_values = [np.array(y[1]) for y in y_train]\n",
    "\n",
    "x_test_values = []\n",
    "for i in range(len(x_test)):\n",
    "    x_test_values.append([])\n",
    "    for row in x_test[i].values:\n",
    "        x_test_values[-1].append(row[1:])\n",
    "y_test_values = [np.array(y[1]) for y in y_test]\n",
    "\n",
    "x_val_values = []\n",
    "for i in range(len(x_val)):\n",
    "    x_val_values.append([])\n",
    "    for row in x_val[i].values:\n",
    "        x_val_values[-1].append(row[1:])\n",
    "y_val_values = [np.array(y[1]) for y in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03898ec0-a4ec-46b0-8902-136b7ccf48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train_values.pickle', 'wb') as file:\n",
    "    pickle.dump(x_train_values, file)\n",
    "\n",
    "with open('y_train_values.pickle', 'wb') as file:\n",
    "    pickle.dump(y_train_values, file)\n",
    "\n",
    "with open('y_test.pickle', 'wb') as file:\n",
    "    pickle.dump(y_test, file)\n",
    "\n",
    "with open('y_val.pickle', 'wb') as file:\n",
    "    pickle.dump(y_val, file)\n",
    "\n",
    "with open('x_test_values.pickle', 'wb') as file:\n",
    "    pickle.dump(x_test_values, file)\n",
    "\n",
    "with open('y_test_values.pickle', 'wb') as file:\n",
    "    pickle.dump(y_test_values, file)\n",
    "\n",
    "with open('x_val_values.pickle', 'wb') as file:\n",
    "    pickle.dump(x_test_values, file)\n",
    "\n",
    "with open('y_val_values.pickle', 'wb') as file:\n",
    "    pickle.dump(y_val_values, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
